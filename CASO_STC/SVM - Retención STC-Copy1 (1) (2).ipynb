{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASO DE NEGOCIO: Modelamiento de Retención de Clientes en Scholastic Travel Company\n",
    "\n",
    "## Sinopsis\n",
    "\n",
    "Scholastic Travel Company (STC) quiere usar los datos de sus clientes para predecir quién comprará un paquete de viaje el próximo año. Los casos presentan datos de 2.389 clientes, donde el conjunto A contiene varios campos de perfil y el conjunto B contiene información adicional del Net Promoted Score (NPS)\n",
    "\n",
    "Este notebook ha sido preparado con información provista en el Caso de Negocios de Harvard UV7579 (Agosto 23, 2018), Retention Modeling at Scholastic Travel Company, elaborado por Anton Ovchinnikov, profesor de Management Science, Operations Management y Customer Analytics, en la escuela de negocios Smith, de Queen’s University en Canadá.\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "Los objetivos del ejercicio son:\n",
    "\n",
    "1.   Entender el problema de negocio presentado y cómo este problema se convierte en un problema de analítica de datos\n",
    "2.   Aplicar técnicas adecuadas en preparación de datos para clasificación\n",
    "3.   Aplicar técnicas adecuadas en limpieza de datos: lidiar con valores faltantes, categorías extrañas\n",
    "4.   Practicar con herramientas avanzadas de analítica de datos como regresión logística (incluyendo la selección de variables Recursive Feature Elimination para Python) y máquinas de vectores de soporte (SVM)\n",
    "5.   Entender las métricas de casificación más comunes: matriz de confusión, curva ROC, Área bajo la curva AUC, para poder comparar modelos analíticos\n",
    "\n",
    "Los principales pasos a seguir son:\n",
    "\n",
    "1.   Asegurar que los paquetes y librerías necesarios están instalados (e instalarlos si no lo están)\n",
    "2.   Cargar los paquetes y librerías necesarios\n",
    "3.   Cargar los datos\n",
    "4.   \"Limpiar\" los datos: necesitaremos (4.1) convertir algunas características en tipos correctos, (4.2) combinar categorías de variables, (4.3) arreglar los valores que faltan, y (4.4) crear dummies (one hot encoding) para las características no numéricas\n",
    "5.   Definir el objetivo (la variable que intentamos predecir) y la matriz de características (todas las demás, excepto el ID)\n",
    "6.   Dividir los datos en entrenamiento y prueba\n",
    "7.   Entrenar (ajustar) el modelo con los datos de entrenamiento \n",
    "8.   Aplicarlo a los datos de prueba \n",
    "9.   Calcular las métricas del modelo y ajustar los hiperparámetros para mejorar esas métricas\n",
    "10.  Exportar las predicciones para la toma de decisiones\n",
    "\n",
    "\n",
    "Consideraremos varios modelos de analítica de datos:\n",
    "\n",
    "1. MÁQUINAS DE VECTORES DE SOPORTE: un método intermedio entre las regresiones y los árboles que se ajusta a planos de menor dimensión para separar los datos en clases con el máximo margen entre ellas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 0: Para iniciar ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasos 1 y 2: Instalar y cargar los paquetes y librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Chequear el ambiente Anaconda y los paquetes/librerías instalados\n",
    "# import sys\n",
    "# !conda env list\n",
    "# !conda list\n",
    "# !conda update --all\n",
    "\n",
    "# Descargar e instalar pandas, numpy, scikit-learn. Podría ser necesario hacerlos desde el prompt de Anaconda\n",
    "# !conda install pandas # pandas includes numpy \n",
    "# !conda install scikit-learn\n",
    "\n",
    "# Paso 2: Cargar los paquetes y librerías necesarios \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, classification_report, confusion_matrix, make_scorer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 3: Cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3: Cargar los datos desde el archivo CSV en el dataframe llamado df.\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\carlo\\Downloads\\04 CSV data -- STC(A)_numerical dates (2).csv\", sep=\";\", header = 0)  \n",
    "df.head() # show the \"head\" -- first 5 rows of the data; note, these are rows 0...4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 4: \"Limpiar\" los datos\n",
    "\n",
    "En este caso, los datos se dejan a propósito ligeramente \"sucios\", es decir, se limpian previamente en cierta medida, pero para efectos de aprendizaje todavía quedan algunos elementos de datos \"sucios\":\n",
    "\n",
    "- Algunos campos de datos (variables, características, columnas) tienen tipos incorrectos, por ejemplo, deberían convertirse de números a categorías.\n",
    "\n",
    "- Algunas variables categóricas tienen demasiados valores (niveles), y algunos de los niveles son demasiado raros: por ejemplo, sólo hay un grupo de Bahamas -- estos datos deberían fusionarse en una categoría más poblada\n",
    "\n",
    "- Faltan algunos datos y hay que sustituirlos o imputarlos\n",
    "\n",
    "- Para concluir la limpieza de los datos, tendremos que crear, por supuesto, variables ficticias (\"one hot encodig\") para las variables categóricas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Limpieza de datos -- parte 1: convertir tipos de datos incorrectos\n",
    "\n",
    "# Algunos de los tipos de datos que maneja Python:\n",
    "# int -- número entero (e.g., 5)\n",
    "# float -- número fraccionario (e.g., 5.25)\n",
    "# object, str -- text (string). Un texto que contiene varios valores no ordenados (e.g., M/F)\n",
    "\n",
    "df.info() # Para chequear qué tipo de datos tenemos \n",
    "\n",
    "# Otros tipos de datos en el paquete pandas:\n",
    "# category -- categoricos, igual que \"factor\" in R (e.g., red/green/blue, or M/F: una lista con varios valores no ordenados)\n",
    "# datetime -- fecha y hora (e.g., 01.01.2020)\n",
    "# bool -- binario (e.g.? yes/no, 1/0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de los datos -- parte 1: conversión de tipos de datos que deberían ser categóricos\n",
    "\n",
    "df['From.Grade'] = df['From.Grade'].astype('category')\n",
    "df['To.Grade'] = df['To.Grade'].astype('category')\n",
    "df['Group.State'] = df['Group.State'].astype('category')\n",
    "df['Is.Non.Annual.'] = df['Is.Non.Annual.'].astype('category')\n",
    "df['Travel.Type'] = df['Travel.Type'].astype('category')\n",
    "df['Poverty.Code'] = df['Poverty.Code'].astype('category')\n",
    "df['CRM.Segment'] = df['CRM.Segment'].astype('category')\n",
    "df['School.Type'] = df['School.Type'].astype('category')\n",
    "df['Parent.Meeting.Flag'] = df['Parent.Meeting.Flag'].astype('category')\n",
    "df['MDR.Low.Grade'] = df['MDR.Low.Grade'].astype('category')\n",
    "df['MDR.High.Grade'] = df['MDR.High.Grade'].astype('category')\n",
    "df['School.Sponsor'] = df['School.Sponsor'].astype('category')\n",
    "df['SchoolGradeTypeLow'] = df['SchoolGradeTypeLow'].astype('category')\n",
    "df['SchoolGradeTypeHigh'] = df['SchoolGradeTypeHigh'].astype('category')\n",
    "df['GroupGradeTypeLow'] = df['GroupGradeTypeLow'].astype('category')\n",
    "df['GroupGradeTypeHigh'] = df['GroupGradeTypeHigh'].astype('category')\n",
    "df['MajorProgramCode'] = df['MajorProgramCode'].astype('category')\n",
    "df['SingleGradeTripFlag'] = df['SingleGradeTripFlag'].astype('category')\n",
    "df['SchoolSizeIndicator'] = df['SchoolSizeIndicator'].astype('category')\n",
    "df['Retained.in.2012.'] = df['Retained.in.2012.'].astype('category')\n",
    "\n",
    "df['Region'] = df['Region'].astype('category')\n",
    "df['Special.Pay'] = df['Special.Pay'].astype('category')\n",
    "df['Income.Level'] = df['Income.Level'].astype('category')\n",
    "df['SPR.Product.Type'] = df['SPR.Product.Type'].astype('category')\n",
    "df['SPR.New.Existing'] = df['SPR.New.Existing'].astype('category')\n",
    "\n",
    "df.info() # Chequeemos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Limpieza de datos -- parte 2: combinar categorías poco frecuentes (\"niveles\")\n",
    "\n",
    "df['Group.State'].value_counts() # Tomemos el ejemplo de la variable Group.State\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Presentamos una función personalizada que llamaremos CombineRareCategories\n",
    "# esta función tiene dos argumentos: el nombre del dataframe (data) y el número mínimo de puntos de datos para seguir \n",
    "# siendo una categoría separada (mincount)\n",
    "# esta función recorrerá todas las columnas del marco de datos y combinará todas las categorías que aparezcan en los \n",
    "# datos menos que el número mínimo de veces en (Other)\n",
    "\n",
    "def CombineRareCategories(data, mincount):\n",
    "    for col in data.columns:\n",
    "        if (type(data[col][0]) == str):\n",
    "            for index, row in pd.DataFrame(data[col].value_counts()).iterrows():\n",
    "                if ( row[0] < mincount):\n",
    "                    df[col].replace(index, 'Other_' + col, inplace = True)\n",
    "                else:\n",
    "                    None\n",
    "\n",
    "# Aplicamos esta función a variables con mincount=10                    \n",
    "CombineRareCategories(df, 10)        \n",
    "\n",
    "df[0:10] # Chequeamos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de datos -- parte 3: Reemplazo/Imputación de datos faltantes\n",
    "\n",
    "pd.DataFrame(df).isna().sum() # Chequeamos si hay datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "# Hay datos no disponibles.  Revisemos el porcentaje de los mismos.\n",
    "nan_percentage = pd.DataFrame(df).isna().sum() / len(pd.DataFrame(df))\n",
    "missing_percentage_df = pd.DataFrame({'column_name': pd.DataFrame(df).columns, 'percent_missing': nan_percentage}).reset_index(drop=True)\n",
    "missing_percentage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.DataFrame(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método:\n",
    "# Variables Categóricas: agregar una nueva categoría 'missing_value' (como si fuera un nuevo color, o género)\n",
    "# Variables Numéricas: reemplazar con la mediana (o la media, o el valor más frecuente, etc.) Un método alterno es\n",
    "# ejecutar una imputación, see here: https://scikit-learn.org/stable/modules/impute.html \n",
    "# + agregamos columnas sustitutas indicando que el valor ha sido imputado\n",
    "\n",
    "# creación de variables sustitutas\n",
    "for col in df:\n",
    "    if df[col].isna().sum() != 0: \n",
    "        df[col + '_surrogate'] = df[col].isna().astype(int)\n",
    "\n",
    "# fijación de variables categóricas\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy='constant')\n",
    "imputer.fit(df.select_dtypes(exclude=['int64','float64']))\n",
    "df[df.select_dtypes(exclude=['int64','float64']).columns] = imputer.transform(df.select_dtypes(exclude=['int64','float64']))\n",
    "           \n",
    "# fijación de variables numéricas \n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy='median')\n",
    "imputer.fit(df.select_dtypes(include=['int64','float64']))\n",
    "df[df.select_dtypes(include=['int64','float64']).columns] = imputer.transform(df.select_dtypes(include=['int64','float64']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examinemos los resultados para la variable \"Poverty.Code\"\n",
    "df[['Poverty.Code','Poverty.Code_surrogate']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examinemos los resultados para la variable \"Special.Pay\"\n",
    "df[['Special.Pay','Special.Pay_surrogate']]\n",
    "df[['FirstMeeting','FirstMeeting_surrogate']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de datos -- parte 4: creación de dummies para variables no numéricas (\"one hot encoding\")\n",
    "\n",
    "df = pd.get_dummies(df, columns = df.select_dtypes(exclude=['int64','float64']).columns, drop_first = True)\n",
    "\n",
    "pd.options.display.max_columns = None # remove the limit on the number of columns by default only 20 are shows\n",
    "\n",
    "df.head()  # nuestro dataset tiene ahora 241 columnas (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 5:  Definición del vector objetivo (y) y la matriz de características (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Retained.in.2012._1']\n",
    "X = df.drop(columns = 'Retained.in.2012._1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 6:  Dividir X, y en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la semilla para el generador de número aleatorios\n",
    "np.random.seed(77300)\n",
    "\n",
    "# Dividimos los datos aleatoriamente en 80% para entrenamiento y 20% para prueba \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.20, stratify=y)\n",
    "# IMPORTANTE: Las muestras están estratificadas, i.e., la proporción de clientes retenidos y no-retenidos es la misma en ambos\n",
    "\n",
    "# Chequeemos los resultados\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x=y_test, palette=\"bright\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasos 7, 8, 9: Desarrollar un modelo con los datos de entrenamiento, Usarlo para predecir los valores en los datos de prueba, Calcular las métricas del modelo, y comparar modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, definimos un conjunto de funciones para calcular las métricas del modelo\n",
    "\n",
    "# Curva ROC\n",
    "def plot_roc(y_test, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1, drop_intermediate = False)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([-0.001, 1.001])\n",
    "    plt.ylim([-0.001, 1.001])\n",
    "    plt.xlabel('1-Specificity (False Negative Rate)')\n",
    "    plt.ylabel('Sensitivity (True Positive Rate)')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Matriz de Confusión: cm[0,0], cm[0,1], cm[1,0], cm[1,1]: tn, fp, fn, tp\n",
    "\n",
    "# Sensitivity\n",
    "def custom_sensitivity_score(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "    return (tp/(tp+fn))\n",
    "\n",
    "# Specificity\n",
    "def custom_specificity_score(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "    return (tn/(tn+fp))\n",
    "\n",
    "# Positive Predictive Value\n",
    "def custom_ppv_score(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "    return (tp/(tp+fp))\n",
    "\n",
    "# Negative Predictive Value\n",
    "def custom_npv_score(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "    return (tn/(tn+fn))\n",
    "\n",
    "# Accuracy\n",
    "def custom_accuracy_score(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "    return ((tn+tp)/(tn+tp+fn+fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo № 1: Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "svm_estimators = []\n",
    "svm_estimators.append(('normalize', MinMaxScaler())) # escalamos los datos\n",
    "svm_estimators.append(('svm', svm.SVC(probability=True))) # definimos SVM con probabilidades \n",
    "     \n",
    "# Definimos el modelo SVM y lo llamamos classifier_SVM\n",
    "Classifier_SVM = Pipeline(svm_estimators, verbose=False)\n",
    "\n",
    "# Entrenamos el modelo classifier_SVM sobre los datos de entrenamiento\n",
    "Classifier_SVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos el modelo desarrollado, para predecir sobre los datos de prueba \n",
    "y_pred_prob = Classifier_SVM.predict_proba(X_test)[:,1] # probabilidades\n",
    "class_threshold = 0.6073\n",
    "y_pred = np.where(y_pred_prob > class_threshold, 1, 0) # clasificación\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos el modelo desarrollado, para predecir sobre los datos de prueba \n",
    "y_pred_prob = Classifier_SVM.predict_proba(X_test)[:,1] # probabilidades\n",
    "class_threshold = 0.6073\n",
    "y_pred = np.where(y_pred_prob > class_threshold, 1, 0) # clasificación\n",
    "\n",
    "# Revisemos las métricas del modelo\n",
    "\n",
    "print('Métricas del modelo de Máquina de Vectores de Soporte: \\n')\n",
    "\n",
    "cm = np.transpose(confusion_matrix(y_test, y_pred))\n",
    "print(\"Matriz de Confusión: \\n\" + str(cm))\n",
    "\n",
    "print(\"                                   Accuracy: \" + str(custom_accuracy_score(y_test, y_pred))) \n",
    "print(\"                       SENSITIVITY (RECALL): \" + str(custom_sensitivity_score(y_test, y_pred)))\n",
    "print(\"                     SPECIFICITY (FALL-OUT): \" + str(custom_specificity_score(y_test, y_pred)))\n",
    "print(\"     POSITIVE PREDICTIVE VALUE, (PRECISION): \" + str(custom_ppv_score(y_test, y_pred)))\n",
    "print(\"                  NEGATIVE PREDICTIVE VALUE: \" + str(custom_npv_score(y_test, y_pred)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob)\n",
    "print(\" AUC: \" + str(roc_auc_score(y_test, y_pred_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos el modelo desarrollado, para predecir sobre los datos de prueba \n",
    "\n",
    "y_pred_prob = Classifier_SVM.predict_proba(X_test)[:,1] # probabilidades\n",
    "class_threshold = 0.5\n",
    "\n",
    "y_pred = np.where(y_pred_prob > class_threshold, 1, 0) # clasificación\n",
    "\n",
    "# Revisemos las métricas del modelo\n",
    "\n",
    "print('Métricas del modelo de Máquina de Vectores de Soporte: \\n')\n",
    "\n",
    "cm = np.transpose(confusion_matrix(y_test, y_pred))\n",
    "print(\"Matriz de Confusión: \\n\" + str(cm))\n",
    "\n",
    "print(\"                                   Accuracy: \" + str(custom_accuracy_score(y_test, y_pred))) \n",
    "print(\"                       SENSITIVITY (RECALL): \" + str(custom_sensitivity_score(y_test, y_pred)))\n",
    "print(\"                     SPECIFICITY (FALL-OUT): \" + str(custom_specificity_score(y_test, y_pred)))\n",
    "print(\"     POSITIVE PREDICTIVE VALUE, (PRECISION): \" + str(custom_ppv_score(y_test, y_pred)))\n",
    "print(\"                  NEGATIVE PREDICTIVE VALUE: \" + str(custom_npv_score(y_test, y_pred)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob)\n",
    "print(\" AUC: \" + str(roc_auc_score(y_test, y_pred_prob)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretación de la curva ROC y el AUC: \n",
    "\n",
    "- Si tomamos un cliente con una probabilidad pronósticada de 99%, uno con una probabilidad de 50%, y uno con una probabilidad del 1%. Esperaríamos que el modelo nos diera una certeza de que el primer cliente será retenido, y una certeza de que el tercero no lo será, pero podríamos estar cómodos con un error grande para el segundo.\n",
    "\n",
    "- La curva ROC muestra justamente eso. Ranquea todos los clientes desde el que tiene la probabilidad más alta de retención hasta la más baja (equivale a variar el umbral desde alto hasta bajo). Comenzando en el origen, mapea todos los clientes en orden descendiente de probabilidad (desde el “mejor” hasta el “peor”). Un clasificador perfecto, con exactitud 100%, primero predeciría correctamente todos los positivos, y luego predeciría correctamente todos los negativos; es decir, la curva iría recto hasta el punto (0,1), y luego cambiaría y sería horizontal hasta el punto (1,1). Esto, por supuesto, no es posible en la práctica, y los “pasos” en la curva reflejan los errores ocasionales que el modelo comete. Un buen modelo cometería pocos errores positivos para los mejores clientes y pocos eroreres negativos para los peores.\n",
    "\n",
    "-  Es importante observar que un modelo que simplemente adivina al azar, tendrá como curva ROC una línea de 45 grados. Tal modelo tendría la misma probabilidad de hacer una predicción correcta que una incorrecta, sin importar si el cliente tiene una alta o baja probabilidad predecida.\n",
    "\n",
    "- En este caso el AUC es 86.26% el cual es un buen resultado. El AUC indica la proporción de parejas concordantes en los datos; en este caso el porcentaje de parejas concordantes es aproximadamente 86.26%. Las parejas concordantes son aquellas parejas de casos positivo y negativo en el dataset para las cuales el modelo de SVM - con ciertos parámetros (UMBRAL) - puede clasificarlos correctamente.\n",
    "\n",
    "- En el dataset de prueba, tenemos 289 positivos (clientes retenidos) y 189 negativos (clientes no retenidos); el número total de parejas (positivos y negativos) es 289 x 189 = 54621, de los cuales el 86.26 % (== 47116) tienen unos parámetros (UMBRAL) del modelo de SVM que pueden clasificarlos correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3: Cargar los datos desde el archivo CSV en el dataframe llamado df_B.\n",
    "\n",
    "df_B = pd.read_csv(r\"C:\\Users\\carlo\\Downloads\\04 CSV data -- STC(B)_numerical dates.csv\", sep=\";\", header = 0)  \n",
    "df_B.head() # show the \"head\" -- first 5 rows of the data; note, these are rows 0...4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_C = pd.merge(df, df_B, on='ID',  how='left')\n",
    "df_C.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_C.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método:\n",
    "# Variables Categóricas: agregar una nueva categoría 'missing_value' (como si fuera un nuevo color, o género)\n",
    "# Variables Numéricas: reemplazar con la mediana (o la media, o el valor más frecuente, etc.) Un método alterno es\n",
    "# ejecutar una imputación, see here: https://scikit-learn.org/stable/modules/impute.html \n",
    "# + agregamos columnas sustitutas indicando que el valor ha sido imputado\n",
    "\n",
    "# creación de variables sustitutas\n",
    "for col in df_C:\n",
    "    if df_C[col].isna().sum() != 0: \n",
    "        df_C[col + '_surrogate'] = df_C[col].isna().astype(int)\n",
    "\n",
    "# fijación de variables categóricas\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy='constant')\n",
    "imputer.fit(df_C.select_dtypes(exclude=['int64','float64']))\n",
    "df_C[df_C.select_dtypes(exclude=['int64','float64']).columns] = imputer.transform(df_C.select_dtypes(exclude=['int64','float64']))\n",
    "           \n",
    "# fijación de variables numéricas \n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy='median')\n",
    "imputer.fit(df_C.select_dtypes(include=['int64','float64']))\n",
    "df_C[df_C.select_dtypes(include=['int64','float64']).columns] = imputer.transform(df_C.select_dtypes(include=['int64','float64']))\n",
    "\n",
    "# Examinemos los resultados para la variable \"Poverty.Code\"\n",
    "df_C[['NPS 2011','NPS 2011_surrogate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yC = df_C['Retained.in.2012._1']\n",
    "XC = df_C.drop(columns = 'Retained.in.2012._1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la semilla para el generador de número aleatorios\n",
    "np.random.seed(77300)\n",
    "\n",
    "# Dividimos los datos aleatoriamente en 80% para entrenamiento y 20% para prueba \n",
    "XC_train, XC_test, yC_train, yC_test = train_test_split(XC, yC, test_size = 0.20, stratify=y)\n",
    "# IMPORTANTE: Las muestras están estratificadas, i.e., la proporción de clientes retenidos y no-retenidos es la misma en ambos\n",
    "\n",
    "# Chequeemos los resultados\n",
    "print(XC_train.shape)\n",
    "print(XC_test.shape)\n",
    "print(yC_train.shape)\n",
    "print(yC_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Ejecución de SVM con todas las variables del dataset completo, y evaluar desempeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "XCS_train = scaler.fit_transform(XC_train)\n",
    "XCS_test = scaler.fit_transform(XC_test)\n",
    "\n",
    "print(XCS_train)\n",
    "print(XCS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desarrollamos un clasificador SVM LINEAL\n",
    "clfl = svm.SVC(kernel='linear', C=1, probability=True, random_state=1234) # Linear Kernel\n",
    "\n",
    "# Entrenamos el modelo usando el dataset de entrenamiento\n",
    "clfl.fit(XCS_train, yC_train)\n",
    "\n",
    "# Importamos el módulo scikit-learn metrics para cálculo de Accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "#Pronosticamos la respuesta para el dataset de prueba\n",
    "#En entrenamiento\n",
    "y_predl_e = clfl.predict(XCS_train)\n",
    "#En prueba\n",
    "y_predl = clfl.predict(XCS_test)\n",
    "\n",
    "#Accuracy del modelo:  Qué tan frecuentemente el clasificador es correcto?\n",
    "#En entrenamiento: \n",
    "print(\"Accuracy - entrenamiento: \",metrics.accuracy_score(yC_train, y_predl_e))\n",
    "#En prueba: \n",
    "print(\"Accuracy - prueba: \",metrics.accuracy_score(yC_test, y_predl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Revisemos las métricas del modelo en entrenamiento\n",
    "\n",
    "print('Métricas del modelo de Máquina de Vectores de Soporte (ENTRENAMIENTO): \\n')\n",
    "\n",
    "cml_e = np.transpose(confusion_matrix(yC_train, y_predl_e))\n",
    "print(\"Matriz de Confusión: \\n\" + str(cml_e))\n",
    "\n",
    "print(\"                                   Accuracy: \" + str(custom_accuracy_score(yC_train, y_predl_e))) \n",
    "print(\"                       SENSITIVITY (RECALL): \" + str(custom_sensitivity_score(yC_train, y_predl_e)))\n",
    "print(\"                     SPECIFICITY (FALL-OUT): \" + str(custom_specificity_score(yC_train, y_predl_e)))\n",
    "print(\"     POSITIVE PREDICTIVE VALUE, (PRECISION): \" + str(custom_ppv_score(yC_train, y_predl_e)))\n",
    "print(\"                  NEGATIVE PREDICTIVE VALUE: \" + str(custom_npv_score(yC_train, y_predl_e)))\n",
    "\n",
    "# Revisemos las métricas del modelo en prueba\n",
    "\n",
    "print('\\n \\nMétricas del modelo de Máquina de Vectores de Soporte (PRUEBA): \\n')\n",
    "\n",
    "cml = np.transpose(confusion_matrix(yC_test, y_predl))\n",
    "print(\"Matriz de Confusión: \\n\" + str(cml))\n",
    "\n",
    "print(\"                                   Accuracy: \" + str(custom_accuracy_score(yC_test, y_predl))) \n",
    "print(\"                       SENSITIVITY (RECALL): \" + str(custom_sensitivity_score(yC_test, y_predl)))\n",
    "print(\"                     SPECIFICITY (FALL-OUT): \" + str(custom_specificity_score(yC_test, y_predl)))\n",
    "print(\"     POSITIVE PREDICTIVE VALUE, (PRECISION): \" + str(custom_ppv_score(yC_test, y_predl)))\n",
    "print(\"                  NEGATIVE PREDICTIVE VALUE: \" + str(custom_npv_score(yC_test, y_predl)))\n",
    "\n",
    "\n",
    "y_pred_prob = clfl.predict_proba(XCS_test)[:,1] # probabilidades\n",
    "y_pred = np.where(y_pred_prob > class_threshold, 1, 0) # clasificación\n",
    "\n",
    "plot_roc(yC_test, y_pred_prob)\n",
    "print(\" AUC: \" + str(roc_auc_score(yC_test, y_pred_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Ejecución de SVM con las 20 variables más importantes (usando RFE), y evaluar desempeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REFERENCIAS SOBRE RFE (Recursive Feature Elimination)\n",
    "### https://towardsdatascience.com/feature-selection-in-python-recursive-feature-elimination-19f1c39b8d15\n",
    "### https://www.kite.com/python/docs/sklearn.feature_selection.RFE\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# create the RFE model for the svm classifier and select attributes\n",
    "rfeSVM = RFE(estimator=clfl, n_features_to_select=20, step=1) \n",
    "rfeSVM.fit(XCS_train, yC_train)\n",
    "\n",
    "ranking = rfeSVM.ranking_.reshape(len(XC_train.columns))\n",
    "\n",
    "# Cuáles son las 20 variables que quedan en el modelo?\n",
    "pd.DataFrame([XC_test.columns,ranking]).transpose().sort_values(1).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenemos el nuevo modelo y llamemoslo classifier_SVML_RFE \n",
    "classifier_SVML_RFE = rfeSVM.fit(XCS_train, yC_train)\n",
    "\n",
    "# Usemos el modelo entrenado para predecir sobre los datos de prueba\n",
    "y_pred_prob = classifier_SVML_RFE.predict_proba(XCS_test)[:,1] # probabilidades\n",
    "y_pred = np.where(y_pred_prob > class_threshold, 1, 0) # clasificación\n",
    "\n",
    "# Revisemos las métricas del modelo después de la selección de variables \n",
    "print('Métricas del modelo de SVM después de la selección de variables: \\n')\n",
    "\n",
    "cm = np.transpose(confusion_matrix(yC_test, y_pred))\n",
    "print(\"Matriz de confusión: \\n\" + str(cm))\n",
    "\n",
    "print(\"                                   Accuracy: \" + str(custom_accuracy_score(yC_test, y_pred))) \n",
    "print(\"                       SENSITIVITY (RECALL): \" + str(custom_sensitivity_score(yC_test, y_pred)))\n",
    "print(\"                     SPECIFICITY (FALL-OUT): \" + str(custom_specificity_score(yC_test, y_pred)))\n",
    "print(\"     POSITIVE PREDICTIVE VALUE, (PRECISION): \" + str(custom_ppv_score(yC_test, y_pred)))\n",
    "print(\"                  NEGATIVE PREDICTIVE VALUE: \" + str(custom_npv_score(yC_test, y_pred)))\n",
    "\n",
    "plot_roc(yC_test, y_pred_prob)\n",
    "print(\" AUC: \" + str(roc_auc_score(yC_test, y_pred_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Con el modelo de 20 variables, desarrollamos un SVM radial sintonizando hiper-parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XCS_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XCS20_train = XCS_train[:, []]\n",
    "XCS20_test = XCS_test[:, []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desarrollamos un clasificador SVM RADIAL\n",
    "clfr = svm.SVC(kernel='rbf', C=1, probability=True, random_state=1234) \n",
    "\n",
    "# Entrenamos el modelo usando el dataset de entrenamiento\n",
    "clfr.fit(XCS20_train, yC_train)\n",
    "\n",
    "#Pronosticamos la respuesta para el dataset de prueba\n",
    "#En entrenamiento\n",
    "y_predr_e = clfr.predict(XCS20_train)\n",
    "#En prueba\n",
    "y_predr = clfr.predict(XCS20_test)\n",
    "\n",
    "#Accuracy del modelo:  Qué tan frecuentemente el clasificador es correcto?\n",
    "#En entrenamiento: \n",
    "print(\"Accuracy - entrenamiento: \",metrics.accuracy_score(yC_train, y_predr_e))\n",
    "#En prueba: \n",
    "print(\"Accuracy - prueba: \",metrics.accuracy_score(yC_test, y_predr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Revisemos las métricas del modelo en entrenamiento\n",
    "\n",
    "print('Métricas del modelo de Máquina de Vectores de Soporte (ENTRENAMIENTO): \\n')\n",
    "\n",
    "cmr_e = np.transpose(confusion_matrix(yC_train, y_predr_e))\n",
    "print(\"Matriz de Confusión: \\n\" + str(cmr_e))\n",
    "\n",
    "print(\"                                   Accuracy: \" + str(custom_accuracy_score(yC_train, y_predr_e))) \n",
    "print(\"                       SENSITIVITY (RECALL): \" + str(custom_sensitivity_score(yC_train, y_predr_e)))\n",
    "print(\"                     SPECIFICITY (FALL-OUT): \" + str(custom_specificity_score(yC_train, y_predr_e)))\n",
    "print(\"     POSITIVE PREDICTIVE VALUE, (PRECISION): \" + str(custom_ppv_score(yC_train, y_predr_e)))\n",
    "print(\"                  NEGATIVE PREDICTIVE VALUE: \" + str(custom_npv_score(yC_train, y_predr_e)))\n",
    "\n",
    "# Revisemos las métricas del modelo en prueba\n",
    "\n",
    "print('\\n \\nMétricas del modelo de Máquina de Vectores de Soporte (PRUEBA): \\n')\n",
    "\n",
    "cmr = np.transpose(confusion_matrix(yC_test, y_predr))\n",
    "print(\"Matriz de Confusión: \\n\" + str(cmr))\n",
    "\n",
    "print(\"                                   Accuracy: \" + str(custom_accuracy_score(yC_test, y_predr))) \n",
    "print(\"                       SENSITIVITY (RECALL): \" + str(custom_sensitivity_score(yC_test, y_predr)))\n",
    "print(\"                     SPECIFICITY (FALL-OUT): \" + str(custom_specificity_score(yC_test, y_predr)))\n",
    "print(\"     POSITIVE PREDICTIVE VALUE, (PRECISION): \" + str(custom_ppv_score(yC_test, y_predr)))\n",
    "print(\"                  NEGATIVE PREDICTIVE VALUE: \" + str(custom_npv_score(yC_test, y_predr)))\n",
    "\n",
    "\n",
    "y_pred_prob = clfr.predict_proba(XCS20_test)[:,1] # probabilidades\n",
    "y_pred = np.where(y_pred_prob > class_threshold, 1, 0) # clasificación\n",
    "\n",
    "plot_roc(yC_test, y_pred_prob)\n",
    "print(\" AUC: \" + str(roc_auc_score(yC_test, y_pred_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen del SVM: \n",
    "\n",
    "- entrenamos el modelo con los hiper-parámetros por defecto\n",
    "- aplicando el modelo al dataset de prueba, obtuvimos AUC=  %\n",
    "- ahora, sintonizaremos los hiper-parámetros del modelo ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
